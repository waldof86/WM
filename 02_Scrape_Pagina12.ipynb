{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Options = Options()\n",
    "Options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(options=Options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = f\"https://www.pagina12.com.ar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\r"
     ]
    }
   ],
   "source": [
    "soup = []\n",
    "inicio_paginado = 100 #permite ir mas lejos\n",
    "limite_paginado = 200 #permite ir mas lejos\n",
    "for i in range(inicio_paginado,limite_paginado):\n",
    "    print(i, end='\\r')\n",
    "    driver.get(f\"{url_base}/buscar?q=milei&page={i}\")\n",
    "    pag =  driver.page_source\n",
    "    soup.append(BeautifulSoup(pag, 'html5lib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\r"
     ]
    }
   ],
   "source": [
    "paginas = []\n",
    "fallos = []\n",
    "for i in range(0,limite_paginado):\n",
    "    print(i, end='\\r')\n",
    "    try:\n",
    "        paginas.append(soup[i].find_all('div', class_='article-item__content'))\n",
    "    except:\n",
    "        fallos.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesado articulo 1499\r"
     ]
    }
   ],
   "source": [
    "noticias = pd.DataFrame(columns=['indice','titulo','fecha','link','source','contenido','copete'])\n",
    "\n",
    "i = -1\n",
    "for pagina in paginas:\n",
    "    for noticia in pagina:\n",
    "        i = i + 1\n",
    "        noticias.loc[i,'indice'] = i\n",
    "        noticias.loc[i,'titulo'] = (noticia.get_text())\n",
    "        noticias.loc[i,'link'] = f\"{url_base}{noticia.find('a')['href']}\"\n",
    "        print(f'Procesado articulo {i}', end='\\r')\n",
    "        #print(f\"Articulo: {i} Titulo: \\n{titulo}\\nLink:\\n{link}\\n-------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articulo 1499 - https://www.pagina12.com.ar/707375-una-procuraduria-especializada-en-apretar-gobernadores-contr\r"
     ]
    }
   ],
   "source": [
    "for index, row in noticias.iterrows():\n",
    "    print(f\"Articulo {row.indice} - {row.link}\", end='\\r')\n",
    "    driver.get(row.link)\n",
    "    pag =  driver.page_source\n",
    "    row.source = BeautifulSoup(pag, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fallos = []\n",
    "for index, row in noticias.iterrows():\n",
    "    #print(f\"Articulo {row.indice} - {row.link}\")\n",
    "    try:\n",
    "        contenido_source = row.source.find('div', class_='section-2-col article-main-content')\n",
    "        row.contenido = contenido_source.get_text()\n",
    "        copete_source = row.source.find('div', class_='section-2-col article-header')\n",
    "        row.copete = copete_source.get_text()\n",
    "        fecha_source = row.source.find('meta', property='article:modified_time')\n",
    "        fecha = int(fecha_source.get('content'))\n",
    "        fecha = datetime.datetime.fromtimestamp(fecha)\n",
    "        row.fecha = fecha\n",
    "    except:\n",
    "        fallos.append(index) #captura los fallos por too many requests\n",
    "        #print(f\"Fallo en row: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corremos de nuevo las lineas donde fall√≥\n",
    "for f in fallos:\n",
    "    try:\n",
    "        row = noticias.loc[f]\n",
    "        print(f\"Articulo {row.indice} - {row.link}\", end='\\r')\n",
    "        driver.get(row.link)\n",
    "        pag =  driver.page_source\n",
    "        row.source = BeautifulSoup(pag, 'html5lib')\n",
    "    except:\n",
    "        print(f\"done\")\n",
    "\n",
    "#luego hay que volver a ejecutar el codigo de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "noticias.drop('source', axis = 1, inplace=True)\n",
    "noticias.to_excel('02_pagina12_parte2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
